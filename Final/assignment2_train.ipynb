{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nmMKcN2FybJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image parameters\n",
        "IMG_SIZE = 227 # AlexNet's input size\n",
        "CHANNELS = 3\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "# *** IMPORTANT: UPDATE THIS PATH ***\n",
        "DATA_DIR = '/content/drive/MyDrive/1roo6NzL3-VI-uWpVYut8aHBun5U36PJU'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/alexnet_student_id_model.h5'\n",
        "ENCODER_SAVE_PATH = '/content/drive/MyDrive/label_encoder.pkl'\n",
        "# ---------------------\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "# Assuming the student ID folders are directly inside DATA_DIR\n",
        "all_student_ids = os.listdir(DATA_DIR)\n",
        "\n",
        "print(f\"Found {len(all_student_ids)} student ID folders.\")\n",
        "\n",
        "# Loop through each student ID folder\n",
        "for student_id in all_student_ids:\n",
        "    student_dir = os.path.join(DATA_DIR, student_id)\n",
        "    if not os.path.isdir(student_dir):\n",
        "        continue\n",
        "\n",
        "    for img_name in os.listdir(student_dir):\n",
        "        img_path = os.path.join(student_dir, img_name)\n",
        "        if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "            images.append(img)\n",
        "            labels.append(student_id)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(images, dtype=\"float32\") / 255.0  # Normalize pixel values\n",
        "y = np.array(labels)\n",
        "\n",
        "print(f\"Total images loaded: {len(X)}\")\n"
      ],
      "metadata": {
        "id": "-VQCakhvF3TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode student IDs into numerical classes\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y)\n",
        "# Convert integers to one-hot encoding\n",
        "y_encoded = to_categorical(integer_encoded)\n",
        "\n",
        "NUM_CLASSES = len(label_encoder.classes_)\n",
        "print(f\"Number of classes (Student IDs): {NUM_CLASSES}\")\n",
        "\n",
        "# SAVE the LabelEncoder object\n",
        "with open(ENCODER_SAVE_PATH, 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "print(f\"Label Encoder saved to: {ENCODER_SAVE_PATH}\")\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bu043XtuF9Pp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_alexnet(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # 1st Convolutional Block\n",
        "    x = Conv2D(96, (11, 11), strides=(4, 4), activation='relu', padding='valid')(inputs)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
        "    x = tf.nn.local_response_normalization(x)\n",
        "\n",
        "    # 2nd Convolutional Block\n",
        "    x = Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
        "    x = tf.nn.local_response_normalization(x)\n",
        "\n",
        "    # 3rd, 4th, 5th Convolutional Layers\n",
        "    x = Conv2D(384, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(384, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    # Fully Connected Block\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Create and compile the model\n",
        "alexnet_model = create_alexnet((IMG_SIZE, IMG_SIZE, CHANNELS), NUM_CLASSES)\n",
        "alexnet_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "alexnet_model.summary()\n"
      ],
      "metadata": {
        "id": "TqLaSHmKGFrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "print(\"Starting model training...\")\n",
        "\n",
        "history = alexnet_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "alexnet_model.save(MODEL_SAVE_PATH)\n",
        "print(f\"\\nModel saved to: {MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "gx5OOIgrGIbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}