# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1upT4R_AXAMn48HyWASK_HNZEj6AJma3-
"""

import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from sklearn.preprocessing import LabelEncoder
import pickle
import os

# --- Configuration ---
# Ensure these files are in the same directory as this script
MODEL_PATH = 'alexnet_student_id_model.h5'
ENCODER_PATH = 'label_encoder.pkl'
IMG_SIZE = 227 # Must match the size used for training
# ---------------------

# 1. Load Model and Label Encoder
try:
    classifier = load_model(MODEL_PATH)
    print(f"Loaded trained model from: {MODEL_PATH}")
except Exception as e:
    print(f"ERROR: Could not load model from {MODEL_PATH}.")
    print("Please ensure the model file is in the same directory.")
    exit()

try:
    with open(ENCODER_PATH, 'rb') as file:
        label_encoder = pickle.load(file)
    print(f"Loaded label encoder from: {ENCODER_PATH}")
except Exception as e:
    print(f"ERROR: Could not load label encoder from {ENCODER_PATH}.")
    print("Please ensure the label_encoder.pkl file is in the same directory.")
    exit()


# 2. Load Face Detector (Haar Cascade)
# This path is relative to your OpenCV installation
face_cascade = cv2.CascadeClassifier(
    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
)

if face_cascade.empty():
    print("ERROR: Could not load Haar Cascade XML file.")
    exit()

# 3. Initialize Webcam
cap = cv2.VideoCapture(0)

if not cap.isOpened():
    raise IOError("Cannot open webcam. Please check camera connection.")

print("\nStarting real-time face recognition. Press 'q' to quit.")
print("Waiting for faces...")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Flip the frame for a more natural mirror effect
    frame = cv2.flip(frame, 1)

    # Convert frame to grayscale for faster face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.1,
        minNeighbors=5,
        minSize=(100, 100)
    )

    for (x, y, w, h) in faces:
        # Draw a rectangle around the detected face
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

        # Extract and preprocess the face region
        face_img = frame[y:y+h, x:x+w]

        try:
            # Resize and normalize for the model
            face_img = cv2.resize(face_img, (IMG_SIZE, IMG_SIZE))
            # Convert to RGB (model was trained on RGB) and normalize
            face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
            face_input = np.expand_dims(face_img, axis=0) / 255.0

            # Predict the student ID
            prediction = classifier.predict(face_input, verbose=0)
            predicted_class_index = np.argmax(prediction)

            # Map index back to student ID string
            predicted_id = label_encoder.inverse_transform([predicted_class_index])[0]
            confidence = prediction[0][predicted_class_index] * 100

            # Display the result
            label_text = f"{predicted_id} ({confidence:.2f}%)"

        except Exception as e:
            label_text = "Processing Error"

        # Put the text label above the bounding box
        cv2.putText(frame, label_text, (x, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

    # Display the resulting frame
    cv2.imshow('Live Student ID Recognition', frame)

    # Break the loop on 'q' press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Clean up
cap.release()
cv2.destroyAllWindows()
print("Webcam stream closed.")